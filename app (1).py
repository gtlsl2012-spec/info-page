import streamlit as st
import time
import pandas as pd
import io
import json
from typing import List, Dict, Any

# Try multiple possible Google GenAI client imports to maximize compatibility in different environments.
GENAI_AVAILABLE = False
genai = None
try:
    import google.generativeai as genai  # older package import
    GENAI_AVAILABLE = True
except Exception:
    try:
        from google import genai  # newer package layout
        GENAI_AVAILABLE = True
    except Exception:
        GENAI_AVAILABLE = False

# ---------------------------
# System prompt (counseling-specific, concise)
# ---------------------------
DEFAULT_SYSTEM_PROMPT = (
    "1. ì‚¬ìš©ìì˜ ê°ì •ê³¼ ê³ ë¯¼ì„ ì§„ì‹¬ìœ¼ë¡œ ê³µê°í•˜ë©°, ë”°ëœ»í•˜ê³  ì¡´ì¤‘í•˜ëŠ” ë§íˆ¬ë¡œ ëŒ€í™”í•˜ì„¸ìš”.\n"
    "2. ì‚¬ìš©ìì˜ ìƒí™©ì„ êµ¬ì²´ì ìœ¼ë¡œ ì´í•´í•˜ê¸° ìœ„í•´ ì–¸ì œ, ì–´ë””ì„œ, ì–´ë–¤ ì¼ì´ ìˆì—ˆëŠ”ì§€ ìì—°ìŠ¤ëŸ½ê²Œ ì§ˆë¬¸í•˜ì„¸ìš”.\n"
    "3. ë‹¨ìˆœí•œ ìœ„ë¡œì— ê·¸ì¹˜ì§€ ë§ê³ , í˜„ì‹¤ì ìœ¼ë¡œ ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ì¡°ì–¸ì´ë‚˜ ë°©í–¥ì„ ì œì‹œí•˜ì„¸ìš”."
)

# Models list (user can choose; exclude -exp)
AVAILABLE_MODELS = [
    "gemini-2.0-flash",
    "gemini-1.0",
    "gemini-1.5",
]

# ---------------------------
# API / Model call wrapper
# ---------------------------
def configure_genai(api_key: str):
    if not GENAI_AVAILABLE:
        raise RuntimeError("GenAI client íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. requirementsë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    # Support both possible clients' configure functions
    if hasattr(genai, "configure"):
        genai.configure(api_key=api_key)
    elif hasattr(genai, "client"):
        # some clients use client.init or similar; attempt generic
        try:
            genai.client.configure(api_key=api_key)
        except Exception:
            pass

def call_gemini_chat(api_key: str, model: str, messages: List[Dict[str, str]], max_retries: int = 5) -> Dict[str, Any]:
    \"\"\"Call Gemini-like chat. Includes simple 429 retry logic with exponential backoff.\"\"\"
    if not GENAI_AVAILABLE:
        raise RuntimeError("GenAI client íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì„¤ì¹˜ í›„ ì‹¤í–‰í•˜ì„¸ìš”.")

    configure_genai(api_key)
    backoff = 1.0
    last_exc = None
    for attempt in range(1, max_retries + 1):
        try:
            # Try a few call patterns to support different client libraries
            if hasattr(genai, "chat") and hasattr(genai.chat, "create"):
                return genai.chat.create(model=model, messages=messages)
            elif hasattr(genai, "create_chat_completion"):
                return genai.create_chat_completion(model=model, messages=messages)
            elif hasattr(genai, "client") and hasattr(genai.client, "chat"):
                return genai.client.chat.create(model=model, messages=messages)
            else:
                # Fallback: try genai.ChatCompletion if present
                if hasattr(genai, "ChatCompletion"):
                    return genai.ChatCompletion.create(model=model, messages=messages)
                raise RuntimeError("ì§€ì›ë˜ì§€ ì•ŠëŠ” GenAI í´ë¼ì´ì–¸íŠ¸ ì¸í„°í˜ì´ìŠ¤ì…ë‹ˆë‹¤.")
        except Exception as e:
            errstr = str(e).lower()
            last_exc = e
            if '429' in errstr or 'rate' in errstr or 'quota' in errstr:
                if attempt < max_retries:
                    time.sleep(backoff)
                    backoff *= 2
                    continue
                else:
                    raise RuntimeError("API rate limit: retries exhausted.") from e
            else:
                # Non-retryable
                raise
    raise last_exc

# ---------------------------
# Optional realtime info fetcher (SerpAPI optional)
# ---------------------------
import requests
def fetch_realtime_info(query: str, serpapi_key: str = None) -> str:
    if not serpapi_key:
        return ""
    try:
        params = {"q": query, "api_key": serpapi_key}
        resp = requests.get("https://serpapi.com/search.json", params=params, timeout=6)
        data = resp.json()
        items = data.get('organic_results') or data.get('organic') or []
        lines = []
        for it in items[:3]:
            title = it.get('title') or ''
            link = it.get('link') or it.get('url') or ''
            snippet = it.get('snippet') or ''
            lines.append(f"- {title}: {snippet} ({link})")
        return "\\n".join(lines)
    except Exception:
        return ""

# ---------------------------
# Streamlit UI
# ---------------------------
st.set_page_config(page_title="Counseling Chatbot (Gemini)", layout="wide")
st.title("ğŸ’¬ ìƒë‹´ ì±—ë´‡ â€” ê°ì •Â·ê³ ë¯¼ ì´í•´ ì¤‘ì‹¬ (Gemini API)")

with st.sidebar:
    st.header("ì„¤ì • / ì„¸ì…˜ ì •ë³´")
    api_key = st.secrets.get('GEMINI_API_KEY') if st.secrets.get('GEMINI_API_KEY') else st.text_input("GEMINI API Key", type="password")
    serpapi_key = st.secrets.get('SERPAPI_KEY') if st.secrets.get('SERPAPI_KEY') else st.text_input("(ì„ íƒ) SerpAPI Key", type="password")
    model = st.selectbox("ëª¨ë¸ ì„ íƒ", AVAILABLE_MODELS, index=0)
    enable_csv = st.checkbox("ëŒ€í™” CSV ìë™ ê¸°ë¡", value=True)
    st.markdown("---")
    st.markdown("**ì„¸ì…˜ ìƒíƒœ**")
    st.write(f"ëª¨ë¸: {model}")
    st.write(f"ì„¸ì…˜ ID: {st.session_state.get('session_id','(new)')}")
    if not api_key:
        st.warning("GEMINI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ì…ë ¥í•˜ê±°ë‚˜ st.secrets['GEMINI_API_KEY']ì— ì„¤ì •í•˜ì„¸ìš”.")

# Initialize session state
if 'history' not in st.session_state:
    st.session_state.history = [{'role':'system', 'content': DEFAULT_SYSTEM_PROMPT}]
if 'full_logs' not in st.session_state:
    st.session_state.full_logs = []
if 'session_id' not in st.session_state:
    st.session_state.session_id = str(int(time.time()))

# Controls
col1, col2, col3 = st.columns([1,1,2])
with col1:
    if st.button("ëŒ€í™” ì´ˆê¸°í™” (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìœ ì§€)"):
        st.session_state.history = [{'role':'system', 'content': DEFAULT_SYSTEM_PROMPT}]
        st.success("ì„¸ì…˜ ì´ˆê¸°í™” ì™„ë£Œ")
with col2:
    if st.button("ëŒ€í™” ì „ë¶€ ì‚­ì œ (ìƒˆ ì„¸ì…˜)"):
        st.session_state.history = [{'role':'system', 'content': DEFAULT_SYSTEM_PROMPT}]
        st.session_state.full_logs = []
        st.session_state.session_id = str(int(time.time()))
        st.success("ìƒˆ ì„¸ì…˜ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
with col3:
    if st.session_state.full_logs:
        df = pd.DataFrame(st.session_state.full_logs)
        csv_bytes = df.to_csv(index=False).encode('utf-8')
        st.download_button("ë¡œê·¸ ë‹¤ìš´ë¡œë“œ (CSV)", csv_bytes, file_name=f"chat_logs_{st.session_state.session_id}.csv", mime='text/csv')

st.subheader("ëŒ€í™”ì°½ â€” ì‚¬ìš©ìì˜ ê°ì •ê³¼ ê³ ë¯¼ì„ ê³µê°í•˜ë©° ìƒë‹´í•˜ì„¸ìš”")

def render_history():
    for turn in st.session_state.history[1:]:
        role = turn['role']
        content = turn['content']
        if role == 'user':
            st.markdown(f"**ì‚¬ìš©ì:** {content}")
        elif role == 'assistant':
            st.markdown(f"**ìƒë‹´ë´‡:** {content}")

render_history()

user_input = st.text_area("ë©”ì‹œì§€ ì…ë ¥", height=140, placeholder="ê°ì •ì´ë‚˜ ê³ ë¯¼ì„ í¸í•˜ê²Œ ì ì–´ì£¼ì„¸ìš”. ìƒë‹´ë´‡ì´ ê³µê°í•˜ê³  ë„ì™€ë“œë¦´ê²Œìš”.")
if st.button("ì „ì†¡") and user_input.strip():
    st.session_state.history.append({'role':'user', 'content': user_input.strip()})
    messages_for_api = [{'role': m['role'], 'content': m['content']} for m in st.session_state.history]
    realtime_summary = fetch_realtime_info(user_input[:160], serpapi_key)
    if realtime_summary:
        messages_for_api.append({'role':'system', 'content': f"[ì‹¤ì‹œê°„ ì •ë³´]\\n{realtime_summary}"})
    try:
        response = call_gemini_chat(api_key=api_key, model=model, messages=messages_for_api)
        resp_text = ""
        try:
            if isinstance(response, dict):
                choices = response.get('choices') or []
                if choices:
                    # common patterns
                    resp_text = choices[0].get('message', {}).get('content') or choices[0].get('text') or ''
                else:
                    resp_text = response.get('content') or str(response)
            else:
                resp_text = getattr(response, 'content', None) or getattr(response, 'response', None) or str(response)
        except Exception:
            resp_text = str(response)
        assistant_message = resp_text or "(ì‘ë‹µì„ ë°›ì•„ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.)"
        st.session_state.history.append({'role':'assistant', 'content': assistant_message})
        if enable_csv:
            st.session_state.full_logs.append({'timestamp': int(time.time()), 'role':'user', 'text': user_input.strip()})
            st.session_state.full_logs.append({'timestamp': int(time.time()), 'role':'assistant', 'text': assistant_message})
        st.experimental_rerun()
    except RuntimeError as e:
        st.warning(f"ëª¨ë¸ í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        preserved = st.session_state.history[-6:]
        st.session_state.history = [{'role':'system', 'content': DEFAULT_SYSTEM_PROMPT}] + preserved
        st.error("ìš”ì²­ì´ ê³¼ë‹¤í•˜ì—¬ ì„¸ì…˜ì„ ìµœê·¼ 6í„´ìœ¼ë¡œ ì¶•ì†Œí•œ ë’¤ ì¬ì‹œì‘í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

st.markdown("---")
st.caption("ì•± ë…¸íŠ¸: GenAI í´ë¼ì´ì–¸íŠ¸ íŒ¨í‚¤ì§€ê°€ ì—†ìœ¼ë©´ ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•´ë„ ëª¨ë¸ í˜¸ì¶œì´ ë¶ˆê°€í•©ë‹ˆë‹¤. requirementsë¥¼ í™•ì¸í•˜ì„¸ìš”.")

with st.expander("ì„¸ì…˜/ë””ë²„ê·¸ ì •ë³´"):
    st.write({'session_id': st.session_state.session_id, 'history_len': len(st.session_state.history)})
    st.json(st.session_state.history)
